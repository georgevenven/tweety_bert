{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Data Into Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "mins_per_fold = 50\n",
    "fold_data_dir = \"/media/george-vengrovski/disk1/decoder_data\"\n",
    "\n",
    "birds_wav_paths = [\n",
    "    \"/media/george-vengrovski/disk2/canary/yarden_data/llb3_data/llb3_songs\",\n",
    "    \"/media/george-vengrovski/disk2/canary/yarden_data/llb11_data/llb11_songs\",\n",
    "    \"/media/george-vengrovski/disk2/canary/yarden_data/llb16_data/llb16_songs\"\n",
    "]\n",
    "\n",
    "song_detection_json = \"files/contains_llb.json\"\n",
    "\n",
    "# Build a mapping from filename to its full path for all birds\n",
    "wav_file_to_path = {}\n",
    "for bird_path in birds_wav_paths:\n",
    "    if os.path.isdir(bird_path):\n",
    "        for fname in os.listdir(bird_path):\n",
    "            if fname.endswith('.wav'):\n",
    "                wav_file_to_path[fname] = os.path.join(bird_path, fname)\n",
    "\n",
    "# Parse the song detection JSON and collect song files and their durations per bird\n",
    "with open(song_detection_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "bird_song_files = {}  # bird_id -> list of (filename, duration_seconds)\n",
    "for entry in data:\n",
    "    if not entry.get('song_present', False):\n",
    "        continue\n",
    "    filename = entry['filename']\n",
    "    if filename not in wav_file_to_path:\n",
    "        continue\n",
    "    bird_id = filename.split('_')[0]\n",
    "    total_duration = 0.0\n",
    "    for seg in entry.get('segments', []):\n",
    "        onset_ms = seg.get('onset_ms', 0)\n",
    "        offset_ms = seg.get('offset_ms', 0)\n",
    "        total_duration += (offset_ms - onset_ms) / 1000.0\n",
    "    if total_duration <= 0:\n",
    "        continue\n",
    "    if bird_id not in bird_song_files:\n",
    "        bird_song_files[bird_id] = []\n",
    "    bird_song_files[bird_id].append((filename, total_duration))\n",
    "\n",
    "# For each bird, randomly assign files to folds so each fold has at least mins_per_fold minutes\n",
    "folds_info = {}  # bird_id -> list of folds, each fold is list of (filename, duration)\n",
    "for bird_id, files in bird_song_files.items():\n",
    "    random.shuffle(files)\n",
    "    folds = []\n",
    "    current_fold = []\n",
    "    current_fold_duration = 0.0\n",
    "    for fname, dur in files:\n",
    "        current_fold.append((fname, dur))\n",
    "        current_fold_duration += dur\n",
    "        if current_fold_duration >= mins_per_fold * 60:\n",
    "            folds.append(current_fold)\n",
    "            current_fold = []\n",
    "            current_fold_duration = 0.0\n",
    "    if current_fold:  # Add any remaining files to a final fold\n",
    "        folds.append(current_fold)\n",
    "    folds_info[bird_id] = folds\n",
    "\n",
    "# Copy files to their respective fold directories with progress bar\n",
    "for bird_id, folds in folds_info.items():\n",
    "    for i, fold in enumerate(folds):\n",
    "        fold_dir = os.path.join(fold_data_dir, bird_id, f\"fold{i+1}\")\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "        print(f\"Copying files for {bird_id} fold {i+1} ({len(fold)} files)...\")\n",
    "        for fname, _ in tqdm(fold, desc=f\"{bird_id} fold{i+1}\", leave=False):\n",
    "            src = wav_file_to_path[fname]\n",
    "            dst = os.path.join(fold_dir, fname)\n",
    "            if not os.path.exists(dst):\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "# Gather fold durations for plotting\n",
    "plot_bird_ids = []\n",
    "plot_fold_names = []\n",
    "plot_fold_minutes = []\n",
    "for bird_id, folds in folds_info.items():\n",
    "    for i, fold in enumerate(folds):\n",
    "        fold_minutes = sum(dur for _, dur in fold) / 60\n",
    "        plot_bird_ids.append(bird_id)\n",
    "        plot_fold_names.append(f\"fold{i+1}\")\n",
    "        plot_fold_minutes.append(fold_minutes)\n",
    "\n",
    "# Plot bar plots showing minutes per fold for each bird\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "bar_labels = [f\"{bird}-{fold}\" for bird, fold in zip(plot_bird_ids, plot_fold_names)]\n",
    "bars = plt.bar(bar_labels, plot_fold_minutes, color='skyblue')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}',\n",
    "             ha='center', va='bottom')\n",
    "plt.title('Minutes of Song Data per Fold (per Bird)', fontsize=14, pad=20)\n",
    "plt.xlabel('Bird-Fold', fontsize=12)\n",
    "plt.ylabel('Total Duration (minutes)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to create embeddings for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'  # Add this before running your code\n",
    "\n",
    "decoding_module = importlib.import_module(\"decoding\")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, mode, bird_name, model_name, wav_folder, song_detection_json_path, num_samples_umap):\n",
    "        self.mode = mode\n",
    "        self.bird_name = bird_name\n",
    "        self.model_name = model_name\n",
    "        self.wav_folder = wav_folder\n",
    "        self.song_detection_json_path = song_detection_json_path\n",
    "        self.num_samples_umap = num_samples_umap\n",
    "        self.num_random_files_spec = 1000  # Default value\n",
    "        self.single_threaded_spec = False  # Default value\n",
    "        self.nfft = 1024  # Default value\n",
    "        self.raw_spectrogram_umap = False  # Default value for store_true flag\n",
    "        self.state_finding_algorithm_umap = \"HDBSCAN\"  # Default value\n",
    "        self.context_umap = 1000  # Default value\n",
    "\n",
    "for root, dirs, files in os.walk(fold_data_dir):\n",
    "    for dir in dirs:\n",
    "        if \"fold\" in dir:\n",
    "            bird = os.path.basename(root)\n",
    "            bird_name_fold = f\"{bird}_{dir}\"\n",
    "            wav_folder = os.path.join(root, dir)\n",
    "            args = Args(\n",
    "                mode=\"single\",\n",
    "                bird_name=bird_name_fold,\n",
    "                model_name=\"BF_Canary_Joint_Run\",\n",
    "                wav_folder=wav_folder,\n",
    "                song_detection_json_path=song_detection_json,\n",
    "                num_samples_umap=\"1e6\"\n",
    "            )\n",
    "            print(f\"Running decoding.py --mode single --bird_name {bird_name_fold} --model_name BF_Canary_Joint_Run --wav_folder {wav_folder} --song_detection_json_path {song_detection_json} --num_samples_umap 1e6\")\n",
    "            decoding_module.main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalulate TweetyBERT, Parameteric, Load and Transform on Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 17:51:15.367380: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-23 17:51:15.391529: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 18\n",
      "Step 25: Train Loss 0.7733 FER = 16.29%, Val Loss = 0.6695\n",
      "Step 50: Train Loss 0.2792 FER = 6.85%, Val Loss = 0.2819\n",
      "Step 75: Train Loss 0.1820 FER = 4.60%, Val Loss = 0.1793\n"
     ]
    }
   ],
   "source": [
    "import sys, pathlib, os, shutil, time\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import umap\n",
    "from umap.parametric_umap import ParametricUMAP # Keep for now, but logic will be commented\n",
    "import hdbscan\n",
    "from hdbscan import approximate_predict\n",
    "\n",
    "sys.path.insert(0, str(pathlib.Path(\"src\").resolve()))\n",
    "from src.decoder import TweetyBertClassifier, SongDataSet_Image, CollateFunction\n",
    "\n",
    "# ── I/O paths ────────────────────────────────────────────────────────────────\n",
    "root      = pathlib.Path().resolve()\n",
    "npz_dir   = root / \"files\"\n",
    "save_dir  = root / \"results\" / \"decoder_eval\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# reduce to two folds for speed; slice each to 10 k frames\n",
    "raw_files = [\n",
    "    \"llb3_fold1.npz\",\n",
    "    \"llb3_fold2.npz\",\n",
    "    \"llb3_fold8.npz\",\n",
    "    \"llb3_fold4.npz\",\n",
    "    \"llb3_fold1.npz\",\n",
    "    \"llb3_fold3.npz\",\n",
    "    \"llb3_fold7.npz\",\n",
    "    \"llb3_fold9.npz\",\n",
    "    \"llb3_fold5.npz\",\n",
    "    \"llb3_fold6.npz\",\n",
    "    \"llb16_fold2.npz\",\n",
    "    \"llb16_fold4.npz\",\n",
    "    \"llb16_fold1.npz\",\n",
    "    \"llb16_fold3.npz\",\n",
    "    \"llb16_fold5.npz\",\n",
    "    \"llb11_fold2.npz\",\n",
    "    \"llb11_fold8.npz\",\n",
    "    \"llb11_fold4.npz\",\n",
    "    \"llb11_fold1.npz\",\n",
    "    \"llb11_fold3.npz\",\n",
    "    \"llb11_fold7.npz\",\n",
    "    \"llb11_fold5.npz\",\n",
    "    \"llb11_fold6.npz\",\n",
    "]\n",
    "MAX_FRAMES = 1_000_000\n",
    "\n",
    "# ── helpers ──────────────────────────────────────────────────────────────────\n",
    "def group_by_bird(fnames: List[str]) -> Dict[str, List[str]]:\n",
    "    d = defaultdict(list)\n",
    "    for f in fnames:\n",
    "        d[f.split(\"_\")[0]].append(f)\n",
    "    return {k: sorted(v) for k, v in d.items()}\n",
    "\n",
    "def load_states_labels(fp: pathlib.Path):\n",
    "    with np.load(fp) as f:\n",
    "        # Return embeddings, spectrograms, hdbscan_labels from file, ground_truth_labels from file\n",
    "        # Use f.get for 's' to be robust if 's' key is missing, though it should be present.\n",
    "        return (f[\"predictions\"][:MAX_FRAMES], # Embeddings\n",
    "                f['s'][:MAX_FRAMES],    # Spectrograms\n",
    "                f[\"hdbscan_labels\"][:MAX_FRAMES],       # HDBSCAN labels from the NPZ file\n",
    "                f[\"ground_truth_labels\"][:MAX_FRAMES])  # Ground truth labels from the NPZ file\n",
    "\n",
    "def time_and_keep(reducer, X):\n",
    "    t0 = time.perf_counter()\n",
    "    Z  = reducer.transform(X)\n",
    "    return Z, time.perf_counter() - t0\n",
    "\n",
    "def time_decoder_forward(model, loader, dev):\n",
    "    model.eval(); t0 = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            _ = model(b[\"spec\"].to(dev))\n",
    "    return time.perf_counter() - t0\n",
    "\n",
    "# ── benchmark ────────────────────────────────────────────────────────────────\n",
    "def benchmark_bird(bird_id: str,\n",
    "                   fold_files: List[str],\n",
    "                   ctx: int = 1_000,\n",
    "                   pumap_epochs: int = 200,          # fewer epochs for test\n",
    "                   dev: str = (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                   model_dir: str | None = None) -> None:\n",
    "\n",
    "    fold_paths = [npz_dir / f for f in fold_files]\n",
    "    csv_path = save_dir / \"timings.csv\"\n",
    "    header   = not csv_path.exists()          # write header only once\n",
    "\n",
    "    for fit_path in fold_paths:\n",
    "        fit_name = fit_path.name\n",
    "        # X_fit for UMAP/PUMAP are the embeddings.\n",
    "        # The TweetyBertClassifier (dec) loads its own data (specs, hdbscan_labels) from fit_path via dec.prepare_data()\n",
    "        X_fit_embeddings, _, _, _ = load_states_labels(fit_path)\n",
    "        X_fit = X_fit_embeddings # Use X_fit as the variable name for UMAP/PUMAP input for consistency\n",
    "\n",
    "        # 1) classic UMAP + HDBSCAN(predict)\n",
    "        umap_red = None # Placeholder if not running UMAP\n",
    "        hdb_u = None    # Placeholder if not running UMAP\n",
    "        # umap_red = umap.UMAP(n_neighbors=30, min_dist=0., n_components=6,\n",
    "        #                      metric=\"euclidean\", low_memory=True,\n",
    "        #                      n_jobs=-1).fit(X_fit)\n",
    "        # if umap_red: # Only fit hdb_u if umap_red was actually run\n",
    "        #     hdb_u = hdbscan.HDBSCAN(min_samples=1, min_cluster_size=1_000,\n",
    "        #                             prediction_data=True) \\\n",
    "        #                     .fit(umap_red.embedding_)\n",
    "\n",
    "        # 2) parametric-UMAP + HDBSCAN(predict)\n",
    "        pumap = None # Placeholder if not running\n",
    "        hdb_p = None # Placeholder if not running\n",
    "        # pumap = ParametricUMAP(n_neighbors=30, min_dist=0., n_components=6, # Keep ParametricUMAP import for now\n",
    "        #                        metric=\"euclidean\", n_epochs=pumap_epochs,    # but comment out its usage\n",
    "        #                        batch_size=2_048, verbose=False).fit(X_fit)\n",
    "        # if pumap: # Only fit hdb_p if pumap was actually run\n",
    "        #     hdb_p = hdbscan.HDBSCAN(min_samples=1, min_cluster_size=1_000,\n",
    "        #                             prediction_data=True) \\\n",
    "        #                     .fit(pumap.embedding_)\n",
    "\n",
    "        # 3) TweetyBert decoder\n",
    "        if model_dir is None:\n",
    "            raise ValueError(\"need model_dir\")\n",
    "        dec_dir = save_dir / f\"{bird_id}__{fit_name}__decoder\"\n",
    "        dec = TweetyBertClassifier(model_dir=model_dir,\n",
    "                                   linear_decoder_dir=str(dec_dir),\n",
    "                                   context_length=ctx)\n",
    "        dec.prepare_data(str(fit_path), test_train_split=0.8)\n",
    "        dec.create_dataloaders(batch_size=256)\n",
    "        dec.create_classifier()\n",
    "        dec.train_classifier(lr=1e-3, desired_total_batches=300,\n",
    "                             batches_per_eval=25, patience=4)\n",
    "        dec_model = dec.classifier_model.to(dev)\n",
    "\n",
    "        # ─ evaluate on *other* fold(s) ───────────────────────────────────────\n",
    "        for eval_path in fold_paths:\n",
    "            if eval_path.name == fit_name:\n",
    "                continue\n",
    "\n",
    "            prefix = f\"{fit_name}__{eval_path.name}\"\n",
    "            results_npz_path = save_dir / f\"{prefix}.results.npz\"\n",
    "            # If results already exist, skip computation for this pair\n",
    "            if results_npz_path.exists():\n",
    "                print(f\"Skipping {results_npz_path} (already exists)\")\n",
    "                row = {\n",
    "                    \"bird\": bird_id, \"fit_fold\": fit_name, \"eval_fold\": eval_path.name,\n",
    "                    \"umap_s_per_row\":   0,\n",
    "                    \"pumap_s_per_row\":  0,\n",
    "                    \"decoder_s_per_row\": 0,\n",
    "                    \"results_path\": str(results_npz_path)\n",
    "                }\n",
    "                pd.DataFrame([row]).to_csv(csv_path, mode=\"a\", header=header, index=False)\n",
    "                header = False\n",
    "                continue\n",
    "\n",
    "            # Load all necessary data from the evaluation fold\n",
    "            X_eval_embeddings, specs_eval, _, ground_truth_labels_eval = load_states_labels(eval_path)\n",
    "            # X_eval_embeddings are for UMAP/PUMAP\n",
    "            # specs_eval are for the decoder\n",
    "            # ground_truth_labels_eval is for the final NPZ output\n",
    "\n",
    "            n_rows_embeddings = len(X_eval_embeddings)\n",
    "            n_frames_spec = specs_eval.shape[0] if specs_eval.ndim > 0 and specs_eval.size > 0 else 0\n",
    "\n",
    "            # classic UMAP timing + preds + emb dump\n",
    "            # if umap_red and hdb_u: # Only run if umap was actually fitted\n",
    "            #     Z_u, t_u = time_and_keep(umap_red, X_eval_embeddings)\n",
    "            #     lbl_u, _ = approximate_predict(hdb_u, Z_u)\n",
    "            # else: # Default values if UMAP is skipped\n",
    "            Z_u, t_u = np.array([]), 0.0\n",
    "            lbl_u = np.array([])\n",
    "\n",
    "            # parametric timing + preds + emb dump\n",
    "            # if pumap and hdb_p: # Only run if pumap was actually fitted\n",
    "            #     Z_p, t_p = time_and_keep(pumap, X_eval_embeddings)\n",
    "            #     lbl_p, _ = approximate_predict(hdb_p, Z_p)\n",
    "            # else: # Default values if pumap is skipped\n",
    "            Z_p, t_p = np.array([]), 0.0\n",
    "            lbl_p = np.array([])\n",
    "\n",
    "            # --- Decoder Evaluation with Actual Spectrograms ---\n",
    "            tmp_eval_dir = dec_dir / \"eval_tmp_actual\" # New name for clarity\n",
    "            shutil.rmtree(tmp_eval_dir, ignore_errors=True)\n",
    "            tmp_eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            pred_dec = np.array([]) # Default if no spec frames\n",
    "            t_d = 0.0\n",
    "\n",
    "            if n_frames_spec > 0:\n",
    "                # Assuming specs_eval from file is (time, freq_bins) e.g., (MAX_FRAMES, 196)\n",
    "                # The TweetyBertClassifier._save_data transposes specs for SongDataSet_Image.\n",
    "                # Spectrograms from file might need the same padding as in TweetyBertClassifier.prepare_data\n",
    "                # current_spec_freq_bins = specs_eval.shape[1]\n",
    "                # expected_freq_bins_after_padding = 196 # Based on dummy_spec and TweetyBertClassifier internals\n",
    "                # if current_spec_freq_bins < expected_freq_bins_after_padding:\n",
    "                #    padding_amount = expected_freq_bins_after_padding - current_spec_freq_bins\n",
    "                #    specs_eval = np.pad(specs_eval, ((0,0), (padding_amount // 2, padding_amount - padding_amount //2 )), 'constant', constant_values=0)\n",
    "                # For now, assume specs_eval has the correct number of freq bins (e.g. 196) as used by the model.\n",
    "\n",
    "                seg_id_eval = 0\n",
    "                for start_idx in range(0, n_frames_spec, ctx):\n",
    "                    seg_len = min(ctx, n_frames_spec - start_idx)\n",
    "                    spec_segment = specs_eval[start_idx : start_idx + seg_len, :]\n",
    "\n",
    "                    spec_segment = np.pad(spec_segment, ((0, 0), (20, 0)), 'constant', constant_values=0)\n",
    "\n",
    "\n",
    "                    if seg_len < ctx: # Pad the segment if it's shorter than context length\n",
    "                        pad_width = ((0, ctx - seg_len), (0, 0))\n",
    "                        spec_segment = np.pad(spec_segment, pad_width, mode='constant', constant_values=0)\n",
    "                    \n",
    "                    # Save with transpose, similar to TweetyBertClassifier._save_data\n",
    "                    np.savez(tmp_eval_dir / f\"{seg_id_eval}.npz\",\n",
    "                             labels=np.zeros(ctx, dtype=np.int64), # Dummy labels for loader\n",
    "                             s=spec_segment.T, # Transpose: (freq_bins, ctx)\n",
    "                             vocalization=np.zeros(ctx, dtype=np.int8)) # Dummy vocalization\n",
    "                    seg_id_eval += 1\n",
    "                \n",
    "                if seg_id_eval > 0:\n",
    "                    eval_set_actual = SongDataSet_Image(tmp_eval_dir,\n",
    "                                                 num_classes=dec.num_classes, # num_classes from training on fit_path\n",
    "                                                 segment_length=ctx,\n",
    "                                                 infinite_loader=False)\n",
    "                    eval_loader_actual = DataLoader(\n",
    "                        eval_set_actual, batch_size=1, shuffle=False, # batch_size=1 for sequential processing\n",
    "                        collate_fn=CollateFunction(segment_length=ctx))\n",
    "\n",
    "                    preds_list = []\n",
    "                    dec_model.eval()\n",
    "                    t0_dec_eval = time.perf_counter()\n",
    "                    with torch.no_grad():\n",
    "                        for batch in eval_loader_actual:\n",
    "                            spec_tensor = (batch[\"spec\"] if isinstance(batch, dict) else batch[0]).to(dev)\n",
    "                            logits = dec_model(spec_tensor) # dec_model is LinearProbeModel, output (B, S, C)\n",
    "                            # Get class prediction for each time step in the segment\n",
    "                            preds_list.append(torch.argmax(logits, dim=2).cpu().numpy()) # (B, S)\n",
    "                    t_d = time.perf_counter() - t0_dec_eval\n",
    "                    \n",
    "                    if preds_list:\n",
    "                        # Concatenate predictions from all segments and truncate to original spec length\n",
    "                        pred_dec_full = np.concatenate([p.squeeze(0) for p in preds_list]) # if batch_size=1\n",
    "                        pred_dec = pred_dec_full[:n_frames_spec]\n",
    "\n",
    "            np.savez_compressed(\n",
    "                results_npz_path,\n",
    "                umap_labels=lbl_u,\n",
    "                umap_embeddings=Z_u,\n",
    "                pumap_labels=lbl_p,\n",
    "                pumap_embeddings=Z_p,\n",
    "                decoder_labels=pred_dec,\n",
    "                ground_truth_labels=ground_truth_labels_eval # Save actual ground truth\n",
    "            )\n",
    "\n",
    "            # Clean up temporary eval files for decoder\n",
    "            shutil.rmtree(tmp_eval_dir, ignore_errors=True)\n",
    "\n",
    "            row = {\n",
    "                \"bird\": bird_id, \"fit_fold\": fit_name, \"eval_fold\": eval_path.name,\n",
    "                \"umap_s_per_row\":   t_u / n_rows_embeddings if n_rows_embeddings > 0 else 0,\n",
    "                \"pumap_s_per_row\":  t_p / n_rows_embeddings if n_rows_embeddings > 0 else 0,\n",
    "                \"decoder_s_per_row\": t_d / n_frames_spec if n_frames_spec > 0 else 0,\n",
    "                \"results_path\": str(results_npz_path)\n",
    "            }\n",
    "            pd.DataFrame([row]).to_csv(csv_path, mode=\"a\", header=header, index=False)\n",
    "            header = False\n",
    "\n",
    "        # Nuke the decoder train/test folders and dir after we are done with them\n",
    "        shutil.rmtree(dec_dir, ignore_errors=True)\n",
    "\n",
    "        if umap_red: del umap_red\n",
    "        if hdb_u: del hdb_u\n",
    "        del dec, dec_model # pumap, hdb_p already handled or placeholders\n",
    "        if pumap: del pumap\n",
    "        if hdb_p: del hdb_p\n",
    "\n",
    "        if dev.startswith(\"cuda\"):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# ── tiny run ─────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    bird_groups = group_by_bird(raw_files)\n",
    "    model_dir_param = str(root / \"experiments\" / \"BF_Canary_Joint_Run\")\n",
    "    for bird, flist in bird_groups.items():\n",
    "        benchmark_bird(bird, flist, model_dir=model_dir_param)\n",
    "    print(\"\\n--- mean sec / frame ---\")\n",
    "    timing_df = pd.read_csv(save_dir / \"timings.csv\")\n",
    "    display(timing_df.groupby(\"bird\")[[\"umap_s_per_row\",\n",
    "                                       \"pumap_s_per_row\",\n",
    "                                       \"decoder_s_per_row\"]].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetybert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
