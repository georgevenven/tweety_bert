{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee374f0",
   "metadata": {},
   "source": [
    "# add p‑values to correlation results for selected smoothing windows\n",
    "\n",
    "this notebook:\n",
    "\n",
    "1. reads one **`all_windows_summary.txt`** file (contains the rₑ and rₗ columns).  \n",
    "2. reads one or more per‑window **`summary_window*.txt`** files (those list every phrase label → lets us infer *n*).  \n",
    "3. for each requested window it computes two‑tailed *p*-values for the entropy (**rₑ**) and duration (**rₗ**) correlations using the exact sample size extracted from the window file.  \n",
    "4. spits out a tidy dataframe and a `p_values_by_window.csv` for easy copy‑pasting into figure legends or SI.\n",
    "\n",
    "> **assumptions**  \n",
    "> * the window id is the integer in the file‑name (`summary_window200.txt` → 200).  \n",
    "> * each line that starts with `Label` inside the window file corresponds to one phrase label ⇒ sample size *n* is the total number of such lines across all birds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3bf27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, pathlib, pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def r_to_p(r: float, n: int) -> float:\n",
    "    \"\"\"\n",
    "    convert a Pearson correlation coefficient to a two-tailed p-value\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    r : float\n",
    "        Pearson correlation coefficient.\n",
    "    n : int\n",
    "        sample size used to compute r (must be > 2).\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    float\n",
    "        two-tailed p-value (0-1). returns 0.0 when n ≤ 2 or |r| == 1.\n",
    "    \"\"\"\n",
    "    if n <= 2 or abs(r) >= 1.0:\n",
    "        return 0.0\n",
    "    t_stat = abs(r) * math.sqrt((n - 2) / (1 - r**2))\n",
    "    from scipy.stats import t as t_dist\n",
    "    return 2.0 * t_dist.sf(t_stat, df=n - 2)\n",
    "\n",
    "\n",
    "def parse_all_windows_summary(path: pathlib.Path) -> Dict[int, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    parse `all_windows_summary.txt` and collect r_e / r_l per window\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    dict[int, dict[str,float]]\n",
    "        {window_size: {'r_e': <float>, 'r_l': <float>}}\n",
    "    \"\"\"\n",
    "    # match:  optional leading spaces → window int → pipe → r_e → pipe → r_l → pipe\n",
    "    row_re = re.compile(r'^\\s*(\\d+)\\s*\\|\\s*([-+]?\\d*\\.?\\d+)\\s*\\|\\s*([-+]?\\d*\\.?\\d+)\\s*\\|')\n",
    "    table: Dict[int, Dict[str, float]] = {}\n",
    "    \n",
    "    for line in path.read_text().splitlines():\n",
    "        m = row_re.match(line)\n",
    "        if m:\n",
    "            w   = int(m.group(1))\n",
    "            r_e = float(m.group(2))\n",
    "            r_l = float(m.group(3))\n",
    "            table[w] = {'r_e': r_e, 'r_l': r_l}\n",
    "    return table\n",
    "\n",
    "\n",
    "def sample_size_from_window(path: pathlib.Path) -> int:\n",
    "    \"\"\"\n",
    "    infer sample size n for a given `summary_window*.txt`\n",
    "    by counting lines that begin with 'Label <int>:' (ignores -1 rows)\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    int\n",
    "        number of phrase labels across all birds in that window file\n",
    "    \"\"\"\n",
    "    lbl_re = re.compile(r'^\\s*Label\\s+\\d+:')\n",
    "    return sum(1 for ln in path.read_text().splitlines() if lbl_re.match(ln))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a148ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== user inputs ====\n",
    "all_windows_summary_path = '/media/george-vengrovski/Desk SSD/TweetyBERT/proxy_metrics/all_windows_summary.txt'\n",
    "summary_window_files = [\n",
    "    '/media/george-vengrovski/Desk SSD/TweetyBERT/proxy_metrics/window_50/summary_window50.txt',\n",
    "    '/media/george-vengrovski/Desk SSD/TweetyBERT/proxy_metrics/window_150/summary_window150.txt',\n",
    "    '/media/george-vengrovski/Desk SSD/TweetyBERT/proxy_metrics/window_200/summary_window200.txt'\n",
    "    ]\n",
    "# ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b227347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>n</th>\n",
       "      <th>r_entropy</th>\n",
       "      <th>p_entropy</th>\n",
       "      <th>r_length</th>\n",
       "      <th>p_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>0.658</td>\n",
       "      <td>2.669144e-08</td>\n",
       "      <td>0.904</td>\n",
       "      <td>5.959747e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>57</td>\n",
       "      <td>0.745</td>\n",
       "      <td>3.026518e-11</td>\n",
       "      <td>0.947</td>\n",
       "      <td>8.466665e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>56</td>\n",
       "      <td>0.771</td>\n",
       "      <td>3.622371e-12</td>\n",
       "      <td>0.957</td>\n",
       "      <td>1.068345e-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window   n  r_entropy     p_entropy  r_length      p_length\n",
       "0      50  57      0.658  2.669144e-08     0.904  5.959747e-22\n",
       "1     150  57      0.745  3.026518e-11     0.947  8.466665e-29\n",
       "2     200  56      0.771  3.622371e-12     0.957  1.068345e-30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse big summary to fetch r-values\n",
    "aws_path = pathlib.Path(all_windows_summary_path).expanduser()\n",
    "r_table = parse_all_windows_summary(aws_path)\n",
    "\n",
    "records=[]\n",
    "for sw in summary_window_files:\n",
    "    sw_path = pathlib.Path(sw).expanduser()\n",
    "    window_id = int(re.search(r'summary_window(\\d+)', sw_path.name).group(1))\n",
    "    n = sample_size_from_window(sw_path)\n",
    "    \n",
    "    if window_id not in r_table:\n",
    "        raise ValueError(f'window {window_id} not found in all_windows_summary.txt')\n",
    "    r_e = r_table[window_id]['r_e']\n",
    "    r_l = r_table[window_id]['r_l']\n",
    "    \n",
    "    records.append({\n",
    "        'window': window_id,\n",
    "        'n': n,\n",
    "        'r_entropy': r_e,\n",
    "        'p_entropy': r_to_p(r_e, n),\n",
    "        'r_length': r_l,\n",
    "        'p_length': r_to_p(r_l, n)\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(records).sort_values('window')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15f4f406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/george-vengrovski/Documents/projects/tweety_bert_paper/results/proxy_metrics/p_values_by_window.csv\n"
     ]
    }
   ],
   "source": [
    "out_csv = '/home/george-vengrovski/Documents/projects/tweety_bert_paper/results/proxy_metrics/p_values_by_window.csv'\n",
    "df.to_csv(out_csv, index=False)\n",
    "print('saved', out_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetybert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
